---
title: "SnapKin Workflow in R"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SnapKin_WorkFlow_R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(SnapKin)
library(PhosR)
```

# Introduction 

In this vignette, we showcase a workflow for using SnapKin with R.
We assume that the required packages and dependencies are installed. 
If not, refer to the README in the repository for more details.
The stages of this workflow are summarised as follows:

- Labelling phosphoproteomic dataset 
- Preprocessing training and test datasets
- Running Python through R with reticulate
- Predict with SnapKin

# Load Dataset

For this vignette, we will be using the ESC dataset.

```{r}
load('../Data/Phospho_ESC.RData')
head(dat)
```
The ESC dataset consists of time-course phosphoproteomic data stored in a matrix *dat*.

# Assign Labels

Since the training set for SnapKin requires labeled data, we begin by identifying 
known substrates for the kinase MTOR. 
To do this, we refer to the PhosphositePlus database using the PhosR package.


```{r}
# Identify sites and sequence information
labels = rownames(dat)
ids = sapply(strsplit(labels, ";"), function(x)paste(x[1], x[2], "", sep=";"))
residue = gsub("[0-9]","", sapply(strsplit(labels, ";"), "[[", 2))
sites = gsub("[A-Z]","", sapply(strsplit(labels, ";"), "[[", 2))
sequences = sapply(strsplit(labels,';'), function(x)x[3])

# Dataframe index of known substrates for MTOR
substrate.ids = which(ids %in% PhosR::PhosphoSite.mouse$MTOR)
y = rep(0, length(ids))
y[substrate.ids] = 1
```

**Note.** The extraction of site and sequence information may vary for different 
Phosphoproteomic datasets.

# SnapKin Training and Test Set

Now that we have binary labels for our dataset, we can construct a dataframe that 
can be used to train a SnapKin model with the help of some helper functions.
To begin, we can construct the training set as a dataframe consisting of the 
phosphoproteomic data and labels denoted by *training_set*.
Additionally, we may also construct a test set which only contains the 
phosphoproteomic data denoted by *test_set*.
From this, we create *PhosphoExperiment* objects for both training and test.
More information on *PhosphoExperiment* objects can be found in the R package 
[PhosR](https://pyanglab.github.io/PhosR/articles/PhosR.html#setting-up-the-phosphoexperiment-object-1).

**Note.** The training_set must have a column labeled *y*, representing a binary 
encoding of whether a site is a known substrate.

```{r}
# Preprocessing datasets 
training_set = data.frame(dat, y)
test_set = data.frame(dat)
# Generate PhosphoExperiment objects
train = PhosphoExperiment(assays=training_set,
                          Sequence=sequences)
test = PhosphoExperiment(assays=test_set,
                          Sequence=c(sequences))
```



## SnapKin Preprocessing: preprocessSnapKin

Now that we have our training set (and test set) formatted appropriately, we may 
use *preprocessSnapKin* in order to construct appropriate dataframes for SnapKin.
Specifically, this function computes motif scores, normalises the dataset, and 
includes a *site* column for labelling purposes based off rownames (or set by 
the user).
We illustrate the various scenarios where *preprocessSnapKin* may be used.

**Note.** *preprocessSnapKin* contains a *train_ids* and *test_ids* argument 
where you may choose how each observation in the test output will be labeled. 
In this example, we label our observations using the `ids` variable. 
If no *test_ids* or *train_ids* is specified, the default label will be the sequence.

### Training and Test Set

In this scenario, we have a labeled training set and a test set (refer to the 
PhosphoExperiment objects [above](#SnapKin-Training-Set)).
*preprocessSnapKin* may be used as follows to create a train and test dataframe 
for SnapKin.

**Note.** The sequence score for the test dataset is based off the labeled training
set. 
Examining the *site* column in `train_df`, each observation has a sequence label 
while in `test_df` each observation has a label format similar to the `ids` variable.

```{r}
# Compute sequence information and returns a list
preprocessed_data = preprocessSnapKin(train=train,
                                      test=test,
                                      test_ids=ids)
# Extract the training and test df
train_df = preprocessed_data$training
test_df = preprocessed_data$test
```

```{r}
train_df
test_df
```


### Training Set 

In some cases, we may just be interested in seeing how our model will predict on 
the training set based off the training set. 
*preprocessSnapKin* can be used to do this as follows 

```{r}
# Compute sequence information and returns a list
preprocessed_data = preprocessSnapKin(train=train)
# Extract the training and test df
train_df = preprocessed_data$training
test_df = preprocessed_data$test
```

In this case, the test dataframe is the same as the training dataframe except it 
doesn't have *y* labels. 
Similarly, we can refer to ids directly

```{r}
# Compute sequence information and returns a list
preprocessed_data = preprocessSnapKin(train=train,
                                      train_ids=ids)
# Extract the training and test df
train_df = preprocessed_data$training
test_df = preprocessed_data$test
```

# SnapKin

Now that our data is ready for SnapKin to use, we can run SnapKin in R with the 
help of r-reticulate. 
For the following to work, we assume that you have created the appropriate conda 
environment as mentioned in the Github repository. 
Our example uses the *SnapKin* conda environment, specifically Tensorflow with CPU.

## Installing Conda Environment 

This step highlights how the appropriate conda environment may be installed using 
R. 
The Conda environment installed is called **SnapKin**.

```{r eval=FALSE}
installSnapkin()
```

**Note.** This step may be skipped if the conda environment has already been installed.

## Activate Conda Environment

We now activate our conda environment, which contains the required dependencies 
to run SnapKin.

```{r eval=FALSE}
# Set the conda environment to SnapKin
reticulate::use_condaenv(condaenv = 'SnapKin', required=TRUE)
# reticulate::use_condaenv(condaenv = 'SnapKin-GPU', required=TRUE)

# Load the SnapKin module
Snapkin = reticulate::import_from_path('SnapKin',path = '../Python/')
```



Since SnapKin takes pandas dataframes as inputs, we convert our training and test 
datasets into pandas dataframes using *r_to_py*.

```{r eval=FALSE}
# Convert the train/test dataset to pandas dataframes.
snapkin_train = reticulate::r_to_py(train_df)
snapkin_test = reticulate::r_to_py(test_df)
```

## Predict with SnapKin

Now that the datasets are in the right format, we can run SnapKin using **snapkin**, 
which is a function implemented in Python. 
We can include various arguments as seen below. 

```{r eval=FALSE}
predictions = Snapkin$snapkin(df_train=snapkin_train,
                              df_test=snapkin_test,
                              verbose=1,
                              num_layers=3,
                              num_snapshots=10,
                              num_epochs=150,
                              batch_size=32,
                              learning_rate=0.01)
```

This function outputs a R dataframe of SnapKin's predictions for the test set 
that can be easily used.

**Note.** A high learning rate may prevents snapshots of SnapKin from converging.

```{r eval=FALSE}
head(predictions)
```










