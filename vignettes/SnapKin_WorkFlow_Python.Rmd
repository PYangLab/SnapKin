---
title: "SnapKin Workflow in Python"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SnapKin_WorkFlow_Python}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(SnapKin)
library(PhosR)
```

# Introduction 

In this vignette, we showcase a workflow for using SnapKin with Python directly. 
The stages of this workflow are summarised as follows:

- Labelling phosphoproteomic dataset 
- Preprocessing training and test datasets
- Creating an arguments file 
- Running on Python

# Load Dataset

For this vignette, we will be using the ESC dataset.

```{r}
load('../Data/Phospho_ESC.RData')
head(dat)
```
The ESC dataset consists of time-course phosphoproteomic data stored in a matrix *dat*.

# Assign Labels

Since the training set for SnapKin requires labeled data, we begin by identifying 
known substrates for the kinase MTOR. 
To do this, we refer to the PhosphositePlus database using the PhosR package.


```{r}
# Identify sites and sequence information
labels = rownames(dat)
ids = sapply(strsplit(labels, ";"), function(x)paste(x[1], x[2], "", sep=";"))
residue = gsub("[0-9]","", sapply(strsplit(labels, ";"), "[[", 2))
sites = gsub("[A-Z]","", sapply(strsplit(labels, ";"), "[[", 2))
sequences = sapply(strsplit(labels,';'), function(x)x[3])

# Dataframe index of known substrates for MTOR
substrate.ids = which(ids %in% PhosR::PhosphoSite.mouse$MTOR)
y = rep(0, length(ids))
y[substrate.ids] = 1
```

**Note.** The extraction of site and sequence information may vary for different 
Phosphoproteomic datasets.

# SnapKin Training and Test Set

Now that we have binary labels for our dataset, we can construct a dataframe that 
can be used to train a SnapKin model with the help of some helper functions.
To begin, we can construct the training set as a dataframe consisting of the 
phosphoproteomic data and labels denoted by *training_set*.
Additionally, we may also construct a test set which only contains the 
phosphoproteomic data denoted by *test_set*.
From this, we create *PhosphoExperiment* objects for both training and test.
More information on *PhosphoExperiment* objects can be found in the R package 
[PhosR](https://pyanglab.github.io/PhosR/articles/PhosR.html#setting-up-the-phosphoexperiment-object-1).

**Note.** The training_set must have a column labeled *y*, representing a binary 
encoding of whether a site is a known substrate.

```{r}
# Preprocessing datasets 
training_set = data.frame(dat, y)
test_set = data.frame(dat)
# Generate PhosphoExperiment objects
train = PhosphoExperiment(assays=training_set,
                          Sequence=sequences)
test = PhosphoExperiment(assays=test_set,
                          Sequence=c(sequences))
```



## SnapKin Preprocessing: preprocessSnapKin

Now that we have our training set (and test set) formatted appropriately, we may 
use *preprocessSnapKin* in order to construct appropriate dataframes for SnapKin.
Specifically, this function computes motif scores, normalises the dataset, and 
includes a *site* column for labelling purposes based off rownames (or set by 
the user).
We illustrate the various scenarios where *preprocessSnapKin* may be used.

**Note.** *preprocessSnapKin* contains a *train_ids* and *test_ids* argument 
where you may choose how each observation in the test output will be labeled. 
In this example, we label our observations using the `ids` variable. 
If no *test_ids* or *train_ids* is specified, the default label will be the sequence.

### Training and Test Set

In this scenario, we have a labeled training set and a test set (refer to the 
PhosphoExperiment objects [above](#SnapKin-Training-Set)).
*preprocessSnapKin* may be used as follows to create a train and test dataframe 
for SnapKin.

**Note.** The sequence score for the test dataset is based off the labeled training
set. 
Examining the *site* column in `train_df`, each observation has a sequence label 
while in `test_df` each observation has a label format similar to the `ids` variable.

```{r}
# Compute sequence information and returns a list
preprocessed_data = preprocessSnapKin(train=train,
                                      test=test,
                                      test_ids=ids)
# Extract the training and test df
train_df = preprocessed_data$training
test_df = preprocessed_data$test
```

```{r}
train_df
test_df
```


### Training Set 

In some cases, we may just be interested in seeing how our model will predict on 
the training set based off the training set. 
*preprocessSnapKin* can be used to do this as follows 

```{r}
# Compute sequence information and returns a list
preprocessed_data = preprocessSnapKin(train=train)
# Extract the training and test df
train_df = preprocessed_data$training
test_df = preprocessed_data$test
```

In this case, the test dataframe is the same as the training dataframe except it 
doesn't have *y* labels. 
Similarly, we can refer to ids directly

```{r}
# Compute sequence information and returns a list
preprocessed_data = preprocessSnapKin(train=train,
                                      train_ids=ids)
# Extract the training and test df
train_df = preprocessed_data$training
test_df = preprocessed_data$test
```


## Saving Datasets

Now that the datasets are in their correct format, we save our datasets as csv 
files.

```{r}
write.csv(train_df,
          '../Example_Python/Example_ESC_MTOR_train.csv',
          row.names=FALSE)
write.csv(test_df,
          '../Example_Python/Example_ESC_MTOR_test.csv',
          row.names=FALSE)
```


# Arguments File

The arguments file is used to provide necessary information, such as hyperparamters and file paths, to run SnapKin. 

An example `arguments.txt` file is provided in the **Data** directory. 

The arguments that may be used in the arguments file are the following:

    train_fp (required)          :: file path to training csv file
    test_fp  (required)          :: file path to test csv file (requires site column for labels)
    save_dir (required)          :: folder path where predictions are saved 
    save_test_name               :: filename for predictions  (default is prediction.csv)
    verbose                      :: training output and logging - (0) none, (1) progress bar, (2) full output 
    num_layers                   :: number of layers in feed forward network 
    num_snapshots                :: number of snapshots to train 
    num_epochs                   :: number of epochs for each snapshot 
    batch_size                   :: the size of each batch during training 
    learning_rate                :: the maximum learning rate - high learning rates may mean the network won't converge 
    
    
# Running with Python

To run SnapKin with Python, we do the following:

- Open the terminal and move to the Python folder.
- Activate conda environment **conda activate SnapKin**

- Run Python **python3 Trainer.py ../Example_Python/arguments.txt**

A csv file of the predictions is generated and saved depending on the argument.txt file.

